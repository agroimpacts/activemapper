---
title: "Improving cropland maps through tight integration of human and machine intelligence"


author:  

- name: Lyndon D. Estes
  affilnum: '1'
  
# - name: Francisco Rodriguez-Sanchez 
#   affilnum: 3
#   email: f.rodriguez.sanc@gmail.com
  
affiliation:

- affilnum: 1
  affil: Graduate School of Geography, Clark University, 950 Main Street, Worcester, MA 01610 USA

#   
# - affilnum: 2
#   affil: Big Name University, Department of R, City, BN, 01020, USA
#   
# - affilnum: 3
#   affil: Estacion Biologica de Donana (EBD-CSIC), E-41092 Sevilla, Spain
    
output:

  pdf_document:
    fig_caption: yes
    fig_width: 7
    fig_height: 7
    keep_tex: yes
    number_sections: no
    template: manuscript.latex
    includes:
      in_header: header.tex

  html_document: null
  
  word_document: null

documentclass: article
classoption: a4paper
capsize: normalsize
fontsize: 11pt
geometry: margin=1in
linenumbers: yes
spacing: doublespacing
footerdate: yes
abstract: False
bibliography: 
  - references.bib
  - knitcitations.bib
csl: ecology.csl

---


```{r setup, include=FALSE, cache=FALSE, message = FALSE}

library(knitr)
library(citr)

#opts_knit$set(root.dir=normalizePath('../'))

### Chunk options: see http://yihui.name/knitr/options/ ###

## Text results
opts_chunk$set(echo = TRUE, warning = TRUE, message = TRUE, include = TRUE)

## Code decoration
opts_chunk$set(tidy = TRUE, comment = NA, highlight = TRUE)

## Cache
opts_chunk$set(cache = 2, cache.path = "output/cache/")

## Plots
opts_chunk$set(fig.path = "output/figures/")


```


```{r knitcitations, echo=FALSE, cache = FALSE}
library(knitcitations)
cleanbib()   
cite_options(citation_format = "pandoc")
```


\singlespace

\vspace{2mm}\hrule
\vspace{-20pt}
# Abstract
The abstract can go either here or in the YAML


\vspace{3mm}\hrule

*Keywords*: rmarkdown, reproducible science

\doublespace

\bleft

# Introduction
How much cropland is on the planet, and how much more will be needed to meet humanity's rapidly growing food demands? The first part of this question is unclear, as existing estimates tend to vary widely [e.g. @FritzHighlightingcontinueduncertainty2011; @Fritzneedimprovedmaps2013], which makes it substantially harder to answer the second part. The reason for these difficulties is because cropland estimates rely heavily on remote sensing-derived landcover maps, which can be notoriously high in error, particularly over regions such as Africa [@Esteslargeareaspatiallycontinuous2018; @FritzComparisonglobalregional2010], where agricultural changes will be largest and the need for an accurate baseline is thus greatest [@EstesReconcilingagriculturecarbon2016; @SearchingerHighcarbonbiodiversity2015].  

<!-- - The problem in general  -->
<!--     - Africa in particular -->
<!--     - Types of analyses that depend on cropland maps -->

Cropland mapping over a region such as Africa is difficult for several reasons. The primary reason relates to the characteristics of characteristics of the region's smallholder-dominated croplands, where field size averages 1-2 ha [@Debatsgeneralizedcomputervision2016; @FritzMappingglobalcropland2015]. This size is small relative to the 30-250 m resolution of the sensors typically used for most landcover mapping efforts, which results in errors due to mixed pixels and aspects of the modifiable area unit problem [@Openshawmillioncorrelationcoefficients1979], in this case the pixel's shape may be poorly matched to that of cropland, and is too coarse to aggregate to approximate that shape at the characteristic scales of crop fields [@Darkmodifiablearealunit2007; @Esteslargeareaspatiallycontinuous2018]. On top of the matter of scale is 1) high intra-class variability of the cropland class, compounded by the fact that these particular croplands can be heavily intergraded with surrounding vegetation [@Debatsgeneralizedcomputervision2016; @Estesplatformcrowdsourcingcreation2016], and 2) the substantial temporal variability within croplands, both within and between seasons. These latter two aspects poses challenges for the classification algorithms that are applied to the imagery.  

These problems arising from cropland characteristics are increasingly being overcome due to technological advances. Recent advances in satellite technology have increased the coverage of high (<5 m) or near-high (10 m) resolution imagery with weekly to near-daily return intervals [@DruschSentinel2ESAOptical2012; @McCabefutureEarthobservation2017]. This spatial and temporal resolution addresses the sensor-scale mismatch, and more effectively captures the intra-seasonal dynamics of cropland, which helps classifiers distinguish cropland from surrounding cover types [@Debatsgeneralizedcomputervision2016; @Defournyrealtimeagriculturemonitoring2019]. On top of this, advances in cloud computing [@GorelickGoogleEarthEngine2017a], the opening of image archives [@WulderglobalLandsatarchive2016], and next generation machine learning approaches [@MaxwellImplementationmachinelearningclassification2018; @ZhuDeeplearningremote2017] are placing large volumes of these moderate to near-high resolution imagery together with the computational and algorithmic resources necessary to classify them at scale. These capabilities are aleady being used to create a new generation of higher resolution (20-30 m) cropland and landcover maps for Africa and other regions [@ChenGloballandcover2015; @ESAESACCILAND; @LesivEvaluationESACCI2017; @XiongNominal30mCropland2017].  

Despite these advances, the highest resolution (<5 m) image sources are still not used to map cropland over large extents because they are commercial and relatively high cost to acquire. As such, map accuracy still remains below desired levels, as many of these newer maps still have accuracies in the 60-75% range for the cropland class [e.g. @LesivEvaluationESACCI2017; @XiongNominal30mCropland2017]. Accuracy may also be compromised because of factors that are new or becoming more pronounced as a consequence of the recent technological gains, particularly with respect to new algorithms and the manner in which these are trained. Advances in machine learning are helping to greatly improve classification skill, but these algorithms generally require large training datasets [@MaxwellImplementationmachinelearningclassification2018], particularly neural network-based "deep-learning" methods (cite). To satisfy this need for more training samples, map-makers increasingly rely on visual interpretation of high resolution satellite or aerial imagery to collect training (or validation) samples [e.g. @XiongNominal30mCropland2017; @ChenGloballandcover2015]. Several platforms have been developed to facilitate such efforts [e.g. @BeyCollectEarthLand2016; @Estesplatformcrowdsourcingcreation2016; @FritzGeoWikionlineplatform2012], which provide convenient and highly scalable tools for training data collection. Visually interpreted training labels present two particular problems. The first is that such labels have inevitable interpretation errors that can vary substantially according to the skill of the interpreter [@Estesplatformcrowdsourcingcreation2016; @WaldnerConflationexpertcrowd2019]. These errors are typically not accounted for in reported accuracy metrics (cite Arthur's paper), thus the degree to which such labelling error impacts map accuracy is unclear. However, studies of how land cover map error propagates through subsequent analyses [@Esteslargeareaspatiallycontinuous2018] suggests training data quality could have a large impact. The second problem is that visual interpretation depends on high resolution imagery (<5 m), as lower resolutions make it difficult for a human analyst to discern cropland. Typically the only practical source for such imagery are "virtual globe" basemaps provided by Microsoft and Google, which are composed of mosaics of various high resolution satellite and aerial image sources that typically span 3-5 years of time within a single country [@LesivCharacterizingspatialtemporal2018]. This within-mosaic temporal variation can set up a temporal mismatch between the imagery being interpreted and the imagery being classified, which are usually from a different source (e.g. Landsat, Sentinel) and selected to represent a single epoch. If a land change occurs in the interval between the two image sets (e.g. a new field was created), this can introduce error into the training data that is then passed on to the classifier. This source of error may be elevated in smallholder-dominated systems, where swidden systems are more comment (cite), or in rapidly developing agricultural frontiers.  

We describe here a cropland mapping system that seeks to leverage the recent advances that help increase mapping accuracy over smallholder systems, while minimizing those newer sources of error that are associated with these advances. 

<!-- , alongside other methodological improvements leading to fusion or synergy maps, which further reduce map error   -->

<!-- - Why cropland mapping is hard -->
<!--     - 3 problems -->
<!--         - The target itself and its spectral variability and the spectral variability of its background -->
<!--             - Spectral and spatial resolution of sensors -->
<!--             - Poses a challenge for classification algorithms, which want both high resolution to be smaller than characteristic field size, but temporal contrast also -->
    - Training data dependence issues
        - Also interact with image resolution issues
        - Increasingly rely on high amounts of training data
        - Human interpretation error (training data quality)
          - Temporal mismatch with classification feedstock (Lesiv paper)
          - Errors in interpreting these sources of imagery
- Review of who does what to solve the problem (probably integrated with problem statement) 
    - croplands.org
- Our approach that tries to solve these three problems
- Within a framework that tightly integrates tightly training data collection
- And handles large-scale computation
- Segmented boundaries
    
# Methods

- Imagery and image processing methods
- Sample grid
- The system
    - Crowdsourcing platform
          - Training and validation data
          - Accuracy assessment
    - Machine learning
          - Feature engineering
          - ML pipeline Apache Spark
    - Iteration cycle
    - Segmentation

# Results

- Image quality and density
- Computational time/resources, including interaction time
- Labeling results/quality
- Impact of features on accuracy
- Accuracy scores by iteration
- Accuracy by label quality
- Segmentation results 
  - field size class distributions
  - Improvement of accuracy

# Discussion

- Left unquantified is how much training on base maps matters

# Acknowledgements


# References
\singlespace

<!-- ```{r write_citations, cache=FALSE, include=FALSE} -->
<!-- write.bibtex(file="knitcitations.bib") -->
<!-- ``` -->

<div id = "refs"></div>


\eleft

\clearpage


<!-- \listoftables -->


\newpage

<!-- ```{r Table1, results='asis', echo=FALSE, cache=FALSE} -->
<!-- kable(head(iris), caption = "A glimpse of the famous *Iris* dataset.") -->
<!-- ``` -->


\newpage

<!-- ```{r Table2, results='asis', echo=FALSE, cache=FALSE} -->
<!-- kable(mtcars[10:16, ], caption = "Now a subset of mtcars dataset.") -->
<!-- ``` -->


\clearpage

<!-- \listoffigures -->


\newpage

<!-- ```{r Fig1, echo=FALSE, fig.cap="Just my first figure with a very fantastic caption.", cache=FALSE} -->
<!-- x <- rnorm(100) -->
<!-- y <- jitter(x, 1000) -->
<!-- plot(x, y) -->
<!-- ``` -->

\newpage

\blandscape

<!-- ```{r Fig2, echo=FALSE, fig.cap="Second figure in landscape format.", cache=FALSE} -->
<!-- a <- sort(rnorm(100)) -->
<!-- b <- c(rep("Group Small", 35), rep("Group Big", 65)) -->
<!-- boxplot(a ~ b) -->
<!-- ``` -->

\elandscape

\clearpage



```{r sessioninfo, echo = FALSE, eval = FALSE}
# set eval = FALSE if you don't want this info (useful for reproducibility) to appear 
sessionInfo()
```

