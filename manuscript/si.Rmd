---
title: "Supporting Information"

author:  

- name: \*Provisional author list\*
  affilnum: '1'

- name: Lyndon D. Estes
  affilnum: '1'
  email: lestes@clarku.edu

- name: Su Ye
  affilnum: '1'

- name: Lei Song
  affilnum: '1'

- name: Ron Eastman
  affilnum: '1'
  
- name: Sitian Xiong
  affilnum: '1'

- name: Tammy Woodard
  affilnum: '1'

- name: Boka Luo
  affilnum: '1'

- name: Dennis McRitchie
  affilnum: '2'

- name: Ryan Avery
  affilnum: '3'

- name: Kelly Caylor
  affilnum: '3'

- name: Stephanie Debats
  affilnum: '4'

- name: SpatialCollective
  affilnum: '5'

- name: Meridia
  affilnum: '6'

- name: Azavea
  affilnum: '7'

affiliation:

- affilnum: 1
  affil: Graduate School of Geography, Clark University, 950 Main Street, Worcester, MA 01610 USA

- affilnum: 2
  affil: Dennis and Sons, Tucson, AZ, USA

- affilnum: 3
  affil: UCSB

- affilnum: 4
  affil: Uber

- affilnum: 5
  affil: SpatialCollective

- affilnum: 5
  affil: Meridia

- affilnum: 5
  affil: Azavea

output:

  pdf_document:
    fig_caption: yes
    fig_width: 7
    fig_height: 7
    keep_tex: yes
    number_sections: yes
    template: manuscript.latex
    includes:
      in_header: header.tex

  html_document: null
  
  word_document: null

documentclass: article
classoption: a4paper
capsize: normalsize
fontsize: 11pt
geometry: margin=1in
linenumbers: false
spacing: doublespacing
footerdate: yes
abstract: The abstract can go either here or below
keywords: rmarkdown, reproducible science
bibliography: 
  - references.bib
  - knitcitations.bib
csl: ecology.csl

---


```{r setup, include=FALSE, cache=FALSE, message = FALSE}
library(knitr)
library(citr)
library(tidyverse)
library(sf)

#opts_knit$set(root.dir=normalizePath('../'))

### Chunk options: see http://yihui.name/knitr/options/ ###

## Text results
opts_chunk$set(echo = TRUE, warning = TRUE, message = TRUE, include = TRUE)

## Code decoration
opts_chunk$set(tidy = TRUE, comment = NA, highlight = TRUE)

## Cache
opts_chunk$set(cache = 2, cache.path = "output/cache/")

## Plots
opts_chunk$set(fig.path = "output/figures/")


```


```{r knitcitations, echo=FALSE, cache = FALSE}
library(knitcitations)
cleanbib()   
cite_options(citation_format = "pandoc")
```


\singlespace

\bleft
# Methods
## Mapping platform

### Digitizing tools
To minimize the risk of topological errors, *mapper*'s polygon digitizing tools prevent drawing that results in self-intersections and overlaps between adjacent polygons. Upon submission, the PostGIS [`ST_MakeValid`](https://www.postgis.net/docs/ST_MakeValid.html) function is applied to each polygon's geometry to clean remaining topological errors upon insertion into the database. 

### Consensus labelling
As described in the main text, the formula used for creating a consensus label is: 

\begin{equation} \label{eq:main}
\mathrm{P(\theta|D)=\sum_{i=1}^{n}P(W_i|D)P(\theta|D, W_i)}
\end{equation}

Where $\theta$ represents the true cover type of a pixel (field or not field), *D* is the worker's label of that field, and *W$_i$* is an individual worker.  Looking in greater details at this equation, the first half of the righthand side of the equation, P(W$_i$|D), is the "prior" for worker *i* for the current site based on their history of scores from prior accuracy assessment assignments. The second term, P($\theta$|D, W$_i$), is the probability that the actual class of the pixel in the current assignment is the class that worker *i*'s says that it is, which is either 0 or 1. There are four possible values for this second term:

\begin{equation} \label{eq:tp}
P(\theta = field|D_i = field) = 1
\end{equation}
\begin{equation} \label{eq:fp}
P(\theta = no field|D_i = field) = 0
\end{equation}
\begin{equation} \label{eq:tn}
P(\theta = no field|D_i = no field) = 1
\end{equation}
\begin{equation} \label{eq:fn}
P(\theta = field|D_i = no field) = 0
\end{equation}

Where equations \ref{eq:tp} and \ref{eq:tn} represent true positives and negatives, respectively, and equation \ref{eq:fp} is a false positive, and equation \ref{eq:fn} is a false negative.  

Coming back to the first term, the calculation of prior probability can be re-expressed as:

\begin{equation} \label{eq:prior}
\mathrm{P(W_i|D) \approx P(D|W_i)P(W_i)}
\end{equation}

Where:

\begin{equation} 
\mathrm{P(D|W_i) \propto exp\left(-\frac{1}{2}BIC_i\right)}
\end{equation}

With BIC being the Bayesian information criterion:

\begin{equation}
\mathrm{BIC = ln(n)k - 2ln(\hat{L})}
\end{equation}


In which *n* is the sample size, *k* is the number of parameters to estimate, and $\hat{L}$ is the maximum likeihood function. In this case, we are only interested in one parameter (the label that maximizes the likelihood function), thus the BIC becomes:

\begin{equation}
\mathrm{BIC \approx -2ln(\hat{L}) = 2ln(p(D|\hat{\theta}, W))}
\end{equation}

After rearranging, we have:

\begin{equation}
\mathrm{P(D|W_i) \propto p(D|\hat{\theta}, W_i))}
\end{equation}

Which is the worker maximum likelihood, which can be computed as:

\begin{equation} \label{eq:pacc1}
\mathrm{P(\theta = field|\hat{\theta}, M_I) = P(D = field|\theta = field, M_I) = \frac{1}{m}\left(\sum_{j}^{m}\frac{tp_j}{tp_j + fn_j} \right)}
\end{equation}

\begin{equation} \label{eq:pacc2}
\mathrm{P(\theta = no field|\hat{\theta}, M_I) = P(D = no field|\theta = no field, M_I) = \frac{1}{m}\left(\sum_{j}^{m}\frac{tn_j}{tn_j + fp_j} \right)}
\end{equation}

Equations \ref{eq:pacc1} and \ref{eq:pacc2} are producer's accuracies, thus the maximum worker likelihood is equivalent to the worker's average producer's accuracy. 

<!-- \ref{eq:prior} represents "mapper likelihood" for the current map: -->

The other component of equation \ref{eq:prior}, P(W$_i$), is the worker's average score over *m* accuracy assessment assignment:  
\begin{equation}
\mathrm{P(W_i) \propto \frac{1}{m}\sum_{j=1}^{m}score_j}
\end{equation}

Thus equation \ref{eq:prior} uses two measures of worker accuracy, 1) their overall average accuracy score multipled by 2) their average producer's accuracy to create a *weight* for their individual maps for the given site. Equation \ref{eq:main} becomes:

\begin{equation} 
\mathrm{P(\theta|D)=\frac{\sum_{i=1}^{n}weight_iP(\theta|D, W_i)}{\sum_{i=1}^{n}weight_i}}
\end{equation}

With $\mathrm{P(\theta|D, W_i)}$ being either 0 or 1. In labelling, if the consensus result for a pixel is: $\mathrm{P(\theta = field|D)}$ > 0.5, then we assign that pixel to the field category, otherwise to the no field category. 

#### Example

To provide an example of this approach in practice, we'll imagine two workers A and B, each with the following histories:

```{r, echo = FALSE}
library(magrittr)
sc <- tibble::tibble(Worker = LETTERS[1:2], `Prod. Acc. (Field)` = c(0.8, 0.62),
                     `Prod. Acc (no field)` = c(0.81, 0.61), 
                     Score = c(0.75, 0.60))
wtA <- sc[1, ]$Score * sc[1, ]$`Prod. Acc. (Field)`
wtB <- sc[2, ]$Score * sc[2, ]$`Prod. Acc (no field)`

# sc
knitr::kable(sc, align = c("r", "c", "c"), format = "pandoc")
```

In this scenario, worker A thinks that the given pixel falls within a field, and worker B thinks it is not a field.  First, we calculate the weights for each worker:

$$
Weight_A = score_A * PA_A(field) = P(W_A)P(D=field|W_A) = `r sc[1, 2]` * `r sc[1, 4]` = `r wtA`
$$

$$
Weight_B = score_B * PA_B(field) = P(W_B)P(D=no field|W_B) = `r sc[2, 3]` * `r sc[2, 4]` = `r wtB`
$$

And then we plug these weights into the full equation:


$$
\mathrm{P(\theta|D)=\frac{\sum_{i=1}^{n}weight_iP(L = field|D, W_i)}{\sum_{i=1}^{n}weight_i}} = \frac{`r wtA` * 1 + `r wtB` * 0}{`r wtA` + `r wtB`} = `r round((wtA * 1 + wtB * 0) / (wtA + wtB), 3)`
$$

Since `r round((wtA * 1 + wtB * 0) / (wtA + wtB), 3)` > 0.5, we label the particular pixel a field.  



### Accuracy assessment
We designed and implemented a map accuracy assessment protocol following procedures summarized by @StehmanKeyissuesrigorous2019. This entailed the creation of a map reference sample, which first entailed designing a sample, and then designing how the sample response would be collected.

#### Map reference sample design
A reference sample should ideally have some randomization involved in the sample selection protocol, and the probabilities for a sample being included should be provided.  There are multiple sample designs that can be chosen, but we employed a stratified sampling design, using the segmented field boundaries to define the strata for field/non-field. To create the sample, we first extracted the centroids for each of the sample grid cells in Ghana. We then intersected the centroid points with the field segments, assigned a class of 1 (cropland) where points intersected a field, and 0 where they didn't (non-cropland). We then removed from this set of points all those that corresponded to model training, validation, or training reference sites. We then extracted a random sample from both the cropland and non-cropland points. To determine the sample size of each, we specified a desired confidence interval using the following formula [@StehmanKeyissuesrigorous2019]:

$$n = \frac{z^2p(1-p)}{d^2}$$
        
Where p is the estimated probability (or mapped class accuracy), and d is the size of the margin of error (1/2 the confidence interval). We selected a d value of 0.03 and assumed that the user's accuracy of the field class would be 0.75 and that of the non-cropland class would be 0.8, returning sample sizes of 800 and 683, respectively. The distribution of the resulting map reference sample is shown in Figure 1.

```{r, echo = FALSE, fig.align='center', out.width="80%", message=FALSE, warning=FALSE, fig.cap="Distribution of the selected map reference sample for the cropland and non-cropland class. "}
africa <- st_read(
  system.file("extdata/africa.geojson", package = "activemapper"), quiet = TRUE,
)
aois <- st_read(system.file("extdata/aois.geojson", package = "activemapper"), 
                quiet = TRUE)
africa_cont <- africa %>% st_union %>% st_sf
ghana <- africa %>% filter(name == "Ghana") %>% select(geometry)

ref_sample <- readr::read_csv(
  here::here("external/reference/map_reference_sample.csv")
)
ref_sample <- ref_sample %>% st_as_sf(coords = c("x", "y"), crs = 4326)

p <- ggplot() + 
  # geom_sf(data = ghana) +
  geom_sf(data = aois) + 
  geom_sf(data = ref_sample, aes(color = factor(class)), size = 0.1) +
  scale_color_manual(values = c("red", "blue"), 
                     labels = c("Non-cropland", "Cropland"), name = "") + 
  theme_light()
p
```

#### Response design
##### Stage 1
We collected the map reference sample on a separate instance of `labeller` set up for the purpose (`validator.crowdmapper.org`). For the sampling unit, we selected a rectangular polygon of ~0.1 ha (0.0002866$^\circ$ resolution), centered on the centroid of each grid cell selected for map reference sample.  Four classes were established for the validation: **cropland**, **non-cropland**, **uncertain but likely cropland**, and **uncertain but likely non-cropland**. The latter two classes were designed to capture information related to swidden dynamics, following the rationale that uncertainty and time since last cropping are likely to be positively correlated. This uncertainty also captures information about the inherent difficulty of the mapping task. Samples were collected by visually interpreting the overlays of PlanetScope composites presented in `labeller`, following the same interpretation protocols used by the labelling team, with the exception that the polygons placed were square and of 0.0002866$^\circ$ resolution. 

The map reference sample was first placed and defined in an initial stage. In this stage, the class of the initial square polygon was determined, and then the polygon was adjusted if it overlapped more than one class. In sites where the initial map reference grid fell on one of the two uncertain classes, a second polygon was placed in the nearest location where a definite cropland or non-cropland interpretation could be made, with the choice determined by whether the uncertain class was more likely cropland or not cropland. The uncertain class was only used for providing insight into fallow cycles, while the second, more certain polygon was used in a second stage of the map reference sample, which was given to multiple independent interpreters (see below). 

The following set of rules were followed in this first, sample placing phase (undertaken by Lyndon Estes):

1. When determining the class corresponding with the initial location of the target grid, IF:
  - More than half of the target falls within what appears to be a clear arable crop field, then assign it to **cropland**. 
  - More than half falls in what is clearly not a field, then assign it to **non-cropland**. 
  - More than half falls in a location where it is harder to tell whether it is cropland or non-cropland, determine whether it is more likely a crop field or not a crop field, and then assign either **uncertain but likely cropland**, or **uncertain but likely non-cropland**.
  
2. After determining the class, IF:
  a. The target polygon is contained entirely within a single clear class AND
      - The class is either **cropland** or **non-cropland** THEN:
        - Digitize a point within the center of the target box, assign appropriate class, and complete the assignment
      - The class belongs to one of the two **uncertain** classes THEN:
      
        - Digitize a square aligned exactly with the initial target polygon, and choose the class **cropland** or **non-cropland** (following the most likely interpretation) and move the new polygon to the nearest location where it can be contained entirely within that clear **cropland** or **non-cropland** class;
        
        - Digitize a point in the middle of the target polygon, and assign it the appropriate label: **cropland** or **non-cropland**. 
        
  b. The target polygon partially overlaps a second class AND:
      - That class is either **cropland** or **non-cropland** THEN:
      
        - Digitize a square aligned exactly with the target polygon, assign the appropriate class, and move the box to the nearest location (shortest possible distance) where it can be contained entirely within that same class.  
  
      - That class is **uncertain** THEN:
    
        - Digitize a square aligned exactly with the target polygon, assign the appropriate **uncertain** class, then move the box to the nearest location (shortest possible distance) where it can be contained entirely within that same **uncertain** class.
        - Digitize a second square aligned exactly with the initial target polygon, and choose the class **cropland** or **non-cropland** (following the most likely interpretation) and move the new polygon to the nearest location where it can be contained entirely within that clear **cropland** or **non-cropland** class.
  

We then 
  - Definition of spatial assessment
  - Definition of classes
  - Reference source
  - Specific information collected from each source
  - Rules for reference class labels
  - How agreement between map and reference classes is defined

##### Stage 2



\clearpage
# Results

```{r, echo = FALSE, out.width="100%", fig.cap="Cropland probability images produced by RandomForest models trained with A) consensus labels, B) the most accurate worker's labels, and C) the least accurate worker's labels.", fig.align='center', message=FALSE}
knitr::include_graphics('figures/si_hml_probs.png')
```



# References
\singlespace


<div id = "refs"></div>


\eleft

\clearpage





```{r sessioninfo, echo = FALSE, eval = FALSE}
# set eval = FALSE if you don't want this info (useful for reproducibility) to appear 
sessionInfo()
```
