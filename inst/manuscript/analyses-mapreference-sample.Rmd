
```{r setup, include=FALSE, cache=FALSE, message = FALSE}
library(sf)
library(dplyr)
library(ggplot2)
library(aws.s3)
```

### Base Datasets

The pre-preparation of base datasets that install with the `activemapper` package is shown in `external/scripts/data_setup.R`. These are loaded in here. 

```{r, eval=FALSE}
aois <- st_read(
  system.file("extdata/aois.geojson", package = "activemapper")
)
# ggplot(data = tiles) + 
#   geom_sf(aes(fill = as.factor(aoi1)), col = "transparent")
```


## Map reference site selection

Use formula from Stehman and Foody (2019) to estimate desired sample size for different classes, using range of expected user's accuracies per class
```{r, fig.height=4, fig.width=4, fig.align="center"}
fdensity <- raster(here("external/data/field_density005.tif")) 
fdensity[fdensity > 1] <- 1

fpoints <- data.table::fread(here("external/data/field_points005.csv")) %>% 
  as_tibble %>% filter(aoi != "3N")

# proportion of Ghana that is cropland, based on density
dropna <- function(x) x[!is.na(x)]
v <- dropna(values(fdensity))
fcropland <- sum(v) / length(v)  # 21.5%
fcropland2 <- (fpoints %>% filter(class == 1) %>% nrow()) / nrow(fpoints)


###! Move this to SI
# sample size function
ref_sample_size <- function(p, z, d) {
  n <- (z^2 * p * (1 - p)) / d^2
  data.frame(p = p, n = n)
}

# sample size
sample_size <- ref_sample_size(seq(0.6, 0.9, 0.05), 1.96, 0.03)

p1 <- ggplot(sample_size) + geom_point(aes(p, n)) + 
  geom_text(aes(p, n, label = round(n)), nudge_x = 0.017) + theme_bw()
p1
```

Remove all points that were used for training, training reference, or  validation. Contained in CSV of sites prepared in `data_prep.R`
```{r, eval = FALSE}
train_val <- readr::read_csv(here("external/data/train_val_sites.csv"))
fpointsr <- fpoints %>% filter(!id %in% unique(train_val$id))
```

Going with sample size of 800 for cropland class, and 683 for non-cropland, per the above.  MOE of 0.03 and 95% confidence interval on assumed cropland 
```{r, eval=FALSE}
# Take weighted average
set.seed(111)
fsample <- fpointsr %>% filter(class == 1) %>% sample_n(size = 800)
set.seed(111)
nofsample <- fpointsr %>% filter(class == 0) %>% sample_n(size = 683)

ref_sample <- bind_rows(fsample, nofsample) %>% 
  mutate(class = as.character(class)) 

# process into format for labeller, needing name and id
mgrid_tb <- data.table::fread(
  system.file("extdata/ghana_grid.csv", package = "activemapper")
) %>% as_tibble()

ref_sample <- left_join(ref_sample %>% select(id, aoi, class), mgrid_tb, 
                        by = "id") 
data.table::fwrite(
  ref_sample, file = here("external/reference/map_reference_sample.csv")
)

ref_sample_labeller <- ref_sample %>% select(name) %>% 
  mutate(run = 0, iteration = 0, processed = TRUE, usage = "train",
         label = TRUE)

# write to s3 bucket as input to new validation instance
s3write_using(
  ref_sample_labeller,
  FUN = readr::write_csv, bucket = "activemapper",
  object = glue::glue("planet/incoming_names_static_validator.csv")
)
# chk <-  s3read_using(
#   readr::read_csv, bucket = "activemapper",
#   object = "planet/incoming_names_static_validator.csv"
# )
# all(ref_sample_labeller == chk)

# ref_sample <- ref_sample %>% st_as_sf(coords = c("x", "y"), crs = 4326)
# ggplot() + geom_sf(data = ghana) +
#   geom_sf(data = ref_sample, aes(color = factor(class)), size = 0.1) + 
#   theme_light()
```

Set up new instance for performing accuracy assessment, using set up functions provided in `labeller` utilities, following doc `setting-up-new-labeller-instance.md` 
```bash
./common/tools/create_ami.sh labeller8 labeller8-29June2020
./common/tools/create_instance.sh ami-0ee381fa2e7c5b33d t2.small labeller-security
./common/tools/create_elasticip.sh validator crowdmapper.org
```
And then on board modification of `validator`. 

Steps: 

- Switched to reformat branch
- Ran `revoke_qualifications.sh`  
- Ran `fire_up_labeller.py`

```python
python common/fire_up_labeller.py --initial 2 --ec2_instance  "validator" --run_id 0 --aoi_index 1 --aoi_name "validator" --github_branch "reformat" --incoming_names_static_path "planet/incoming_names_static_validator.csv"  --security_group_id "sg-0a8bbc91697d6a76b" --secret_key <key> --db_user <user> --db_pwd <pwd> --github_token <token> --aws_access <access> --aws_secret <secret> --aws_region "us-east-1"
```

Had to change variables manually in `config.yaml` after this to point to correct catalogs. 

- Then run `Rscript spatial/update_db.R`
- Update DB configurations: Set parameters for running validation sample, remembering that the size of the cell for the target will be about 1/10 of a hectare (0.0001433 degrees)

```{r, eval=FALSE}
gcs <- unname(unlist(st_crs(ghana))[2])
ref_ss <- sample(1:nrow(ref_sample), 10)
ref_dt <- data.table::data.table(ref_sample %>% select(-aoi, -fwts))[ref_ss, ]
point_to_gridpoly(ref_dt, 0.0001433, gcs, gcs) %>% 
  st_area() %>% units::set_units("ha")
```

Updating
```{r, eval = FALSE}
update_tbl <- tibble(
  key = c("Hit_AvailTarget", "Hit_FqaqcPercentage", "Hit_MaxAssignmentsF", 
    "Hit_QaqcPercentage", "KMLdlat", "KMLdlon", "Hit_StandAlone"), 
  value = c(5, 100, 1, 0, 0.0001433, 0.0001433, "true")
)

host <- "validator.crowdmapper.org"
con <- DBI::dbConnect(RPostgreSQL::PostgreSQL(), host = host,
                      dbname = "Africa", user = dinfo$db_username,
                      password = dinfo$db_password)
for(i in 1:nrow(update_tbl)) {
  update_sql <- glue::glue(
    "UPDATE configuration SET value={update_tbl[i, 'value']} ",
    "WHERE key='{update_tbl[i, 'key']}'"
  )
  print(update_sql)
  dbExecute(con, update_sql)
}

fs <- tbl(con, "kml_data") %>% collect() %>% filter(kml_type == "F")
# all(fs$name %in% ref_sample$name)

DBI::dbDisconnect(con)
```

And made three categories for validation: annualcropland, noncropland, unsure, entering those manually in database. 

Next, start the system running to create hits. Use an R chunk to execute from chunk using a system call
```{r, eval=FALSE}
cmd <- glue::glue("ssh mapper@validator.crowdmapper.org ", 
                  "python labeller/common/crontab_runner.py --hits T")
system(cmd)

# check whether daemons are running and creating hits
system("ssh mapper@validator.crowdmapper.org ps -ef | grep mapper")
system(glue::glue("ssh mapper@validator.crowdmapper.org ",
                  "labeller/common/tools/list_hits.py"))
```


Quick check to see if size of mapping target is correct--map box on qualification test and then check size
```{r, eval=FALSE}
user_sql <- "SELECT name, try, category, geom_clean FROM qual_user_maps"
user_polys <- suppressWarnings(st_read(con, query = user_sql))
user_polys %>% st_area()  # 0.1 ha

# compare to grid
grid_dt <- data.table::data.table(
  mgrid_tb %>% filter(name == gsub("_1", "", user_polys$name))
)
grid_poly <- point_to_gridpoly(grid_dt, 0.005 / 2, gcs, gcs)
grid_poly %>% st_area() / user_polys %>% st_area()

plot(st_geometry(grid_poly))
plot(st_geometry(user_polys), add = TRUE)
```

Then grant a qualification
```{r, eval=FALSE}
system(glue::glue("ssh mapper@validator.crowdmapper.org ",
                  "labeller/common/tools/grantQualification.py ", 
                  "<email>"))
```


### Distribution of points 
Map reference sample so far
```{r, eval=FALSE}
host <- "validator.crowdmapper.org"
con <- DBI::dbConnect(RPostgreSQL::PostgreSQL(), host = host,
                      dbname = "Africa", user = dinfo$db_username,
                      password = dinfo$db_password)
user_sql <- "SELECT name, category, geom_clean FROM user_maps"
user_polys <- suppressWarnings(st_read(con, query = user_sql))
pt_nms <- unique(gsub("_.*", "", user_polys$name))

pts <- tbl(con, "master_grid") %>% filter(name %in% pt_nms) %>% 
  select(name, x, y) %>% collect()
pts <- pts %>% st_as_sf(coords = c("x", "y"), crs = 4326)

ggplot() + geom_sf(data = aois) + 
  geom_sf(data = pts, size = 0.2) + theme_linedraw()
```


#### Old below here
## Map reference site selection

Now read in and assess accuracy. Grab probability images for AOI1
```{r, eval=FALSE}
library(aws.s3)
library(raster)

# create master_grid extent, get list of probability images, download fpool 
# (for checking)
aois <- st_read(here("external/data/aois.geojson"))
mgrid_ext <- raster(extent(-17.541, 51.459, -35.46, 37.54), res = 0.05)
pimgs <- get_bucket_df(bucket = "activemapper", 
                       prefix = "classified-images/1_whole_test") %>% as_tibble
fpool1 <- s3read_using(FUN = readr::read_csv, 
                       object = "planet/f_pool_1.csv", bucket = "activemapper")
host <- "labeller1.crowdmapper.org"
con <- DBI::dbConnect(RPostgreSQL::PostgreSQL(), host = host, 
                      dbname = "Africa", user = "postgis", password = pw)
mgrid <- tbl(con, "master_grid") %>% filter(name %in% local(fpool1$name)) %>% 
  collect()
kml_data <- tbl(con, "kml_data") %>% filter(kml_type == "F") %>% collect()
# mgrid %>% st_as_sf(coords = c("x", "y")) %>% st_geometry %>% plot

# strip out row, col from names of probability images, and convert them to x, y
# from dummy master_grid
sstr <- "classified-images/1_whole_test/image_"
pimgs <- pimgs %>% select(Key) %>% 
  mutate(row = gsub("c*.*_r|.tif", "", gsub(sstr, "", Key))) %>% 
  mutate(col = gsub("c|_r*.*.tif", "", gsub(sstr, "", Key))) %>% 
  select(Key, row, col)
pimgs_xy <- bind_cols(pimgs, 
                      x = xFromCol(mgrid_ext, as.numeric(pimgs$col) + 1),
                      y = yFromRow(mgrid_ext, as.numeric(pimgs$row) + 1)) %>%
  st_as_sf(coords = c("x", "y"), crs = 4326)

# use xy to extract tile ids
tiles <- read_sf(here("inst/extdata/ghana_tiles.geojson"))
tiles_xy <- st_intersection(tiles, pimgs_xy)
tiles_xy <- st_intersection(tiles_xy, aois %>% select(aois)) %>% as_tibble() %>%
  select(tile, row, col, aois)
tiles_rc <- inner_join(tiles_xy, tiles %>% select(tile)) %>% st_as_sf() %>% 
  select(aois, tile, row, col)
# ggplot(aois) + geom_sf() + geom_sf(data = tiles_xy) +
#   theme_void()

# select grid cell coordinates for reference cells, and then use those to 
# intersect with tiles to get row, col for probability images
ref_xys <- mgrid %>% filter(name %in% ref_aoi1$name) %>% 
  distinct(id, name, x, y) %>% st_as_sf(coords = c("x", "y"), crs = 4326)
# which(ref_xys$name %in% kml_data$name)  # confirm no reference sites intersect
ref_xys_tiles <- st_intersection(ref_xys, tiles_rc) %>% as_tibble

# Then use to get probability image values
# ref_xys_tiles %>% distinct(row, col)
dup_tiles <- ref_xys_tiles %>% filter(duplicated(tile)) %>% pull(tile)
# ref_xys_tiles %>% filter(tile %in% dup_tiles)
unique_ref_tiles <- ref_xys_tiles %>% distinct(tile) %>% pull %>% sort
ref_pvals <- lapply(unique_ref_tiles, function(x) {  # x <- unique_ref_tiles[6]
  print(x)
  tile <- ref_xys_tiles %>% filter(tile == x) 
  ref <- ref_aoi1 %>% filter(name %in% tile$name)
  prob_tile <- pimgs %>% 
    filter(row == unique(tile$row) & col == unique(tile$col))
  prob_tiler <- raster(paste0("/vsis3/activemapper/", prob_tile$Key))
  pvals <- extract(prob_tiler, ref)
  v <- do.call(rbind, lapply(pvals, function(x) {
    tibble(mu = mean(x), sd = sd(x), n = length(x))
  }))
  bind_cols(ref, v) %>% select(name, rid, cls, mu, sd, n)
})
ref_pvals <- do.call(rbind, ref_pvals)
ref_pvals_tb <- ref_pvals %>% as_tibble
ref_pvals_tb %>% ggplot() + geom_boxplot(aes(x = cls, y = mu))

tp <- ref_pvals_tb %>% filter(cls == "f" & mu > 50) %>% count
fn <- ref_pvals_tb %>% filter(cls == "f" & mu < 50) %>% count
fp <- ref_pvals_tb %>% filter(cls == "n" & mu > 50) %>% count
tn <- ref_pvals_tb %>% filter(cls == "n" & mu < 50) %>% count

# ref_pvals_tb %>% filter(cls == "f" & mu > 40) %>% count
# ref_pvals_tb %>% filter(cls == "n" & mu > 40) %>% count
ref_pvals_tb %>% filter(cls == "n" & mu < 40) %>% count
laref_pvals_tb %>% filter(cls == "u" & between(mu, 30, 70))
ref_pvals_tb %>% filter(cls == "u" & (mu < 30 | mu > 70))

(tp + tn) / (tp + tn + fp + fn)

ref_pvals_tb %>% filter(cls == "n" & mu > 50)

```


